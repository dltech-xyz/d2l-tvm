

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-06 10:42:09
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-06 10:47:20
 * @Description:
 * @TODO::
 * @Reference:
-->

＃ GPU架构

更广泛地说，我们在:numref:`tab_cpu_gpu_compare`中比较了本书中使用的CPU和GPU之间的规格差异，其中GPU包括[Tesla P100]（https://images.nvidia.com/content/pdf/tesla/whitepaper  /pascal-architecture-whitepaper.pdf）（在Colab中使用），[Tesla V100]（https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf）（在Amazon中配备）  EC2 P3实例）和[Tesla T4]（https://www.nvidia.com/content/dam/zh-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf  ）（在Amazon EC2 G4实例中配备）。

:比较常用的CPU和GPU，`x`表示不支持。  \ $^*$:Tesla P100使用FP32 CUDA内核处理FP16。

|硬件 | Intel E5-2686 v4 | Tesla P100 | Tesla V100 | Tesla T4 |
|------|------|------|------|------|
| 时钟频率 (GHz) | **3** | 1.48 | 1.53 | 1.59 |
| # cores | 16 | 56 | **80** | 40 |
| # FP64 AUs per core | 4 | **32** | **32** | x |
| # FP32 AUs per core | 8 | **64** | **64** | **64** |
| # FP16 AUs per core | x | x$^*$ | **8** | **8** |
| 缓存每核心 (KB) | **320** | 64 | 128 | 64 |
| 共享缓存 (MB)| **45** | 4 | 6 | 6 |
| 内存 (GB) | **240** | 16 | 16 | 16 |
| 最大内存带宽 (GB/sec) | 72 | 732 | **900** | 300 |
| FP64 TFLOPS | 0.38 | 4.7 | **7.8** | x |
| FP32 TFLOPS | 0.77 | 9.3 | **15.7** | 8.1 |
| FP16 TFLOPS | x | 18.7 | **125.3** | 65 |
:label:`tab_cpu_gpu_compare`

## 小结
GPU在概念上与CPU具有相似的架构，但是速度更快。
